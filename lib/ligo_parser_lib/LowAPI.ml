(* Functor to build a standalone parser with printers *)

(* Vendor dependencies *)

open Core
module Region  = Simple_utils.Region
module Ne      = Nonempty_list
module Pos     = Simple_utils.Pos
module Std     = Simple_utils.Std
module Snippet = Simple_utils.Snippet
module Lexbuf  = Simple_utils.Lexbuf

(* Generic signature of tokens *)

module type TOKEN =
  sig
    type token
    type t = token

    val to_lexeme : token -> string list
    val to_region : token -> Region.t
    val is_eof    : token -> bool
  end

(* Generic signature of input lexers *)

module type LEXER =
  sig
    module Token : TOKEN
    type token = Token.t

    type message = string Region.reg

    val scan_token : no_colour:bool -> Lexing.lexbuf -> (token, message) result

    val used_tokens : unit -> token list (* Scanned tokens *)

    val clear : unit -> unit
  end

(* The signature generated by Menhir with an additional type
   definition for [ast]. *)

module type PARSER =
  sig
    type token
    type tree

    (* The monolithic API. *)

    exception Error

    val main : (Lexing.lexbuf -> token) -> Lexing.lexbuf -> tree

    (* The incremental API. *)

    module MenhirInterpreter : MenhirLib.IncrementalEngine.EVERYTHING
           with type token = token

    module Incremental :
      sig
        val main :
          Lexing.position -> tree MenhirInterpreter.checkpoint
      end

    (* The recovery API. *)

    module Recovery :
      sig
        include Merlin_recovery.RECOVERY_GENERATED
                with module I := MenhirInterpreter

        val default_value : Region.t -> 'a MenhirInterpreter.symbol -> 'a
      end
  end

(* Parser errors for the Incremental API of Menhir *)

module type PAR_ERR =
  sig
    val message : int -> string
  end

(* Parser configuration *)

module type DEBUG_CONFIG =
  sig
    (* We assume that positions refer to bytes or code points. It
       mostly affects the position of synthesized tokens in the error
       recovery mode because Menhir requires to convert [Pos.t] type
       to the poorer representation, that is [Lexing.position]. *)

    val mode : [`Byte | `Point]

    (* Enable debug printing in the recovery algorithm. The argument
       is the path to a log file.
         * [None] means no trace recovery;
         * [Some None] means to use stdout;
         * [Some (Some path)] means to use file [path]. *)

    val trace_recovery : string option option
  end

module type S =
  sig
    type token
    type tree

    type message = string Region.reg

    type error = {
      used_tokens : token list;
      message     : message
    }

    type pass_error =
      Parsing of error
    | Lexing  of error
    | System  of error

    type 'src parser = 'src -> (tree, pass_error) result

    (* Monolithic API of Menhir *)

    type file_path = string

    val mono_from_lexbuf  : no_colour:bool -> Lexing.lexbuf parser
    val mono_from_channel : no_colour:bool -> In_channel.t  parser
    val mono_from_string  : no_colour:bool -> string        parser
    val mono_from_file    : no_colour:bool -> file_path     parser

    (* Incremental API of Menhir without recovery on error *)

    val incr_from_lexbuf  : no_colour:bool -> (module PAR_ERR) -> Lexing.lexbuf parser
    val incr_from_channel : no_colour:bool -> (module PAR_ERR) -> In_channel.t  parser
    val incr_from_string  : no_colour:bool -> (module PAR_ERR) -> string        parser
    val incr_from_file    : no_colour:bool -> (module PAR_ERR) -> file_path     parser

    (* Incremental API with recovery *)

    (* The type ['src recovery_parser] denotes parsers with recovery
       on error. The results are one of the following:

         * [Ok (tree, [])] if the input of type ['src] contains a
           syntactically valid contract;

         * [Ok (repaired_tree, errors)] in case of syntax errors;

         * [Error errors] for non-syntactical errors, e.g. the input
           is not found or a lexer error occurred. *)

    type 'src recovery_parser =
      'src -> (tree * message list, message Ne.t) result

    (* Parsing with recovery from various sources *)

    val recov_from_lexbuf  : no_colour:bool -> (module PAR_ERR) -> Lexing.lexbuf recovery_parser
    val recov_from_channel : no_colour:bool -> (module PAR_ERR) -> In_channel.t  recovery_parser
    val recov_from_string  : no_colour:bool -> (module PAR_ERR) -> string        recovery_parser
    val recov_from_file    : no_colour:bool -> (module PAR_ERR) -> file_path     recovery_parser

    (* Formatting syntax error messages *)

    val format_error : no_colour:bool -> file:bool -> string -> Region.t -> string Region.reg
  end

(* The functor integrating the parser with its errors *)

module Make (Lexer  : LEXER)
            (Parser : PARSER with type token = Lexer.Token.t)
            (Debug  : DEBUG_CONFIG) : S with type token = Lexer.Token.t
                                         and type tree = Parser.tree =
  struct
    type token = Lexer.Token.t
    type tree = Parser.tree
    type message = string Region.reg

    type error = {
      used_tokens : token list;
      message     : message
    }

    type pass_error =
      Parsing of error
    | Lexing  of error
    | System  of error

    type 'src parser = 'src -> (Parser.tree, pass_error) result

    (* Errors and error messages *)

    let get_current_token_region lexbuf : Region.t * token list =
      let used_tokens = Lexer.used_tokens () in
      match used_tokens |> List.rev with
        current_token :: _ ->
          Lexer.Token.to_region current_token, used_tokens
      | [] ->
          (* This case happens if, and only if, there are no
             tokens in the input. *)
          let file = Lexing.(lexbuf.lex_curr_p.pos_fname) in
          let region =
            if String.(file <> "") then
              Region.min ~file (* Start of the file *)
            else Region.ghost (* No pertinent region *)
          in region, used_tokens

    let format_error ~no_colour ~file value (region: Region.t) =
      let value =
        if file then
          sprintf "%s%s"
            (Format.asprintf "%a" (Snippet.pp_lift ~no_colour) region)
            (Std.redden value)
        else
          let header =
            region#to_string
              ~file
              ~offsets:true (* TODO: Options.offsets *)
              `Point
          in sprintf "%s:\n%s" header value
      in Region.{region; value}

    let wrap_parse_error ~no_colour lexbuf (message: string) : error =
      let region, used_tokens = get_current_token_region lexbuf in
      let message = format_error ~no_colour ~file:true message region
      in {used_tokens; message}

    exception LexingError of error

    let menhir_lexer ~no_colour lexbuf =
      match Lexer.scan_token ~no_colour lexbuf with
        Ok token -> token
      | Error message ->
          let used_tokens = Lexer.used_tokens () in
          raise (LexingError {used_tokens; message})

    (* THE MONOLITHIC API *)

    let mono_menhir ~no_colour lexbuf_of source : (Parser.tree, pass_error) result =
      let lexbuf = lexbuf_of source in
      let menhir_lexer = menhir_lexer ~no_colour in
      try Ok (Parser.main menhir_lexer lexbuf) with
        LexingError error ->
          Error (Lexing error)
      | Parser.Error -> (* Menhir exception *)
          Error (Parsing (wrap_parse_error ~no_colour lexbuf "Syntax error."))

    let mono_from_lexbuf  ~no_colour = mono_menhir ~no_colour (fun x -> x)
    let mono_from_channel ~no_colour = mono_menhir ~no_colour Lexing.from_channel
    let mono_from_string  ~no_colour = mono_menhir ~no_colour Lexing.from_string

    type file_path = string

    let lexbuf_from_file path
        : (Lexing.lexbuf * (unit -> unit), error) result =
      try
        let in_chan = In_channel.create path in
        let lexbuf  = Lexing.from_channel in_chan in
        let ()      = Lexbuf.reset_file path lexbuf in
        Ok (lexbuf, fun () -> In_channel.close in_chan)
      with Sys_error msg ->
        let region  = Region.min ~file:path in
        let message = Region.{region; value=msg}
        in Error {used_tokens=[]; message}

    let mono_from_file ~no_colour path =
      match lexbuf_from_file path with
        Error error -> Error (System error)
      | Ok (lexbuf, close) ->
          let tree = mono_menhir ~no_colour (fun x -> x) lexbuf
          in close (); tree

    (* THE INCREMENTAL API *)

    module Inter = Parser.MenhirInterpreter

    (* The call [state checkpoint] extracts the number of the current
       state out of a parser checkpoint. The case [None] denotes the
       case of an error state with an empty LR stack: Menhir does not
       know how to determine that state. Until this is fixed, we
       return [None] and a generic error message (see function
       [message] below.) *)

    let state checkpoint : int option =
      let stack = function
        Inter.HandlingError env -> Some (Inter.stack env)
      |                       _ -> None in
      match stack checkpoint with
        None -> None
      | Some state ->
          let open MenhirLib.General in
          match Lazy.force state with
            Nil -> None
          | Cons (Inter.Element (s,_,_,_), _) -> Some (Inter.number s)

    (* The parser has suspended itself because of a syntax error. *)

    let get_error_message (module ParErr : PAR_ERR) checkpoint : string =
      match state checkpoint with
        (* A MenhirLib limitation (see [state]) when a syntax error
           occurs before a token was read. We work around. *)
        None -> "Syntax error.\nHint: Is the input empty?"
      | Some state ->
          match ParErr.message state with
            (* Default error message (unfinished mapping) *)
            "<YOUR SYNTAX ERROR MESSAGE HERE>\n" ->
              Printf.sprintf "Syntax error #%i." state
          | msg -> msg
            (* Likely a build error, but we work around it: *)
          | exception Stdlib.Not_found -> "Syntax error."

    exception ParsingError of string

    let raise_on_failure (module ParErr : PAR_ERR) checkpoint =
      let msg = get_error_message (module ParErr) checkpoint
      in raise (ParsingError msg)

    (* The parser has successfully produced a semantic value. *)

    let success v = v

    (* Converting [Pos.t] into [Lexing.position] and vice verse.

       IMPORTANT: This conversion is lossy because the
       [Lexing.position] cannot store all information about byte and
       code point positions that is contained in the [Pos.t].

       The position is an offset from the beginning of the line or
       file that is counted in terms of bytes or Unicode code
       points. Obviously, if source code contains Unicode symbols that
       occupy several bytes (like β) they are distanced. So [Pos.t]
       stores both kind of offsets, but [Lexing.position] does not and
       can remember only part of the former. Another part and the
       distance between them will be lost.

       So, we temporarily decided to keep only one part correct
       depending on [mode] that is a part of the API. For example, if
       [mode] equals to [`Point] then [Lexing.position] contains code
       point offsets and it is interpreted like that when will be
       converted back to [Pos.t]. The unknown part will be a copy of
       the known one just to fill it.

       The drawback is that one part of [Pos.t] for synthesized
       tokens, for which we have to retrieve location from menhir
       interface, is incorrect. But we assume that in a certain mode
       (e.g. [`Point]) the compiler uses only certain terms of the
       position.  *)

    let to_pos (mode : [`Byte | `Point]) (pos : Lexing.position)
        : Simple_utils.Pos.t =
      (* Note: [Pos.from_byte (Lexing.dummy_pos) != Pos.ghost] *)
      if Stdlib.(pos = Lexing.dummy_pos) then
          Pos.ghost
      else
      (* Note: assumed that [Pos.from_byte] keeps
         [(point_bol, point_num) = (byte.pos_bol, byte.pos_cnum)]
         So both branch do the same: copy data into both byte part and code
         point part of [Pos.t] *)
      match mode with
        `Byte  -> Pos.from_byte pos
      | `Point -> Pos.from_byte pos

    (* Wrapping the lexer within a token supplier according to the [mode] *)

    let of_pos (mode : [`Byte | `Point])
        : Simple_utils.Pos.t -> Lexing.position =

      (* Packing code point offsets into a [Lexing.position] *)

      let to_point pos =
        (* Note: [Pos.from_byte (Lexing.dummy_pos) <> Pos.ghost] *)
        if pos#is_ghost then Lexing.dummy_pos
        else {
            pos_fname = pos#file;
            pos_lnum  = pos#line;
            pos_bol   = pos#point_bol;
            pos_cnum  = pos#point_num } in

      (* Packing byte offsets into a [Lexing.position] *)

      let to_byte pos = pos#byte in

      match mode with
        `Byte  -> to_byte
      | `Point -> to_point

    (* Wrap lexer in supplier according [mode] *)

    let lexer_lexbuf_to_supplier mode lexer lexbuf =
      Lexer.clear ();
      fun () ->
        let token       = lexer lexbuf in
        let start, stop = (Lexer.Token.to_region token)#pos
        in token, of_pos mode start, of_pos mode stop

    (* Incremental parsing *)

    let incr_menhir ~no_colour lexbuf_of (module ParErr : PAR_ERR) source =
      let lexbuf      = lexbuf_of source in
      let supplier    = lexer_lexbuf_to_supplier
                          Debug.mode (menhir_lexer ~no_colour) lexbuf in
      let failure     = raise_on_failure (module ParErr) in (* Exception *)
      let interpreter = Inter.loop_handle success failure supplier in
      let module Incr = Parser.Incremental in
      let parser      = Incr.main lexbuf.Lexing.lex_curr_p in
      let tree =
        try Ok (interpreter parser) with
          LexingError error -> Error (Lexing error)
        | ParsingError msg  -> Error (Parsing (wrap_parse_error ~no_colour lexbuf msg))
      in tree

    let incr_from_lexbuf  ~no_colour = incr_menhir ~no_colour (fun x -> x)
    let incr_from_channel ~no_colour = incr_menhir ~no_colour Lexing.from_channel
    let incr_from_string  ~no_colour = incr_menhir ~no_colour Lexing.from_string

    let incr_from_file ~no_colour (module ParErr : PAR_ERR) path =
      match lexbuf_from_file path with
        Error error -> Error (System error)
      | Ok (lexbuf, close) ->
          let tree = incr_from_lexbuf ~no_colour (module ParErr) lexbuf
          in (close (); tree)

    (* Incremental parsing with recovery *)

    (* The type ['src recovery_parser] denotes parsers with recovery
       on error. The results are one of the following:

         * [Ok (tree, [])] if the input of type ['src] contains a
           syntactically valid contract;

         * [Ok (repaired_tree, errors)] in case of syntax errors;

         * [Error errors] for non-syntactical errors, e.g. the input
           is not found or a lexer error occurred. *)

    type 'src recovery_parser =
      'src -> (Parser.tree * message list, message Ne.t) result

    module EltPrinter =
      struct
        module I = Inter

        let print str =
          match Debug.trace_recovery with
            None -> ()
          | Some opt ->
              let out_chan =
                match opt with
                  None      -> stdout
                | Some path -> Out_channel.create path
              in Printf.fprintf out_chan "%s" str

        let print_symbol (Inter.X s) =
          print @@ Parser.Recovery.print_symbol s

        let print_element = None

        let print_token t =
          let lexemes = Lexer.Token.to_lexeme t
          in List.iter ~f:print lexemes
      end

    module type PRINTER = Merlin_recovery.PRINTER with module I = Inter

    module TracingPrinter : PRINTER =
      Merlin_recovery.MakePrinter (EltPrinter)

    let checkpoint_to_string = function
      Inter.InputNeeded _   -> "InputNeeded"
    | Inter.Accepted _      -> "Accepted"
    | Inter.Rejected        -> "Rejected"
    | Inter.AboutToReduce _ -> "AboutToReduce"
    | Inter.HandlingError _ -> "HandlingError"
    | Inter.Shifting _      -> "Shifting"

    module RecoverWithDefault =
      struct
        include Parser.Recovery

        (* Because we cannot restore both byte and point position
           correctly another part is assumed to be equal. Assuming
           that [Pos.from_byte] preserves the invariant [(point_bol,
           point_num) = (byte.pos_bol, byte.pos_cnum)] *)

        (* Note: Consistent with [lexer_lexbuf_to_supplier] *)

        (* let convert mode position : Pos.t =
          if Caml.(position = Lexing.dummy_pos) then Pos.ghost
          else match mode with
                 `Byte  -> Pos.from_byte position
               | `Point -> Pos.from_byte position *)

        let default_value loc sym =
          let open Custom_compiler_libs.Location in
          let convert = to_pos Debug.mode in
          let reg = Region.make ~start:(convert loc.loc_start)
                                ~stop:(convert loc.loc_end)
          in Parser.Recovery.default_value reg sym

        let guide _ = false

        let use_indentation_heuristic = false
      end

    module R = Merlin_recovery.Make
                 (Inter) (RecoverWithDefault) (TracingPrinter)

    module Recover =
      struct
        (* The variants of ['a intermediate_step] mean the following:

             * [Correct (InputNeeded env)] means that variants of
               [checkpoint] are considered as invalid intermediate
               steps because we cannot resume parsing with the new
               token.

             * [Recovering (failure_checkpoint, candidates)] *)

        type 'a intermediate_step =
          Correct    of 'a Inter.checkpoint
        | Recovering of 'a Inter.checkpoint * 'a R.candidates

        (* The variant [InternalError] is returned in impossible match
           cases or a logic error in the module [Merlin_recovery]. *)

        type 'a step =
          Intermediate  of 'a intermediate_step
        | Success       of 'a
        | InternalError of string

        (* Moves the parser through [Shifting] and [AboutToReduce]
           checkpoints like in the simple [loop_handle] from MenhirLib. *)

        let inputNeededExpected = function
          Inter.InputNeeded _ | Inter.Accepted _ | Inter.HandlingError _
        | Inter.Shifting _ | Inter.AboutToReduce _ | Inter.Rejected as cp ->
            Format.sprintf "Expected InputNeeded checkpoint, but got %s"
                           (checkpoint_to_string cp)

        (* Moves parser through [Shifting] and [AboutToReduce]
           checkpoints like in simple [loop_handle] from MenhirLib. *)

        let rec check_for_error checkpoint
          : ('a step, 'a Inter.checkpoint) result =
          match checkpoint with
            Inter.InputNeeded _   -> Ok (Intermediate (Correct checkpoint))
          | Inter.Accepted x      -> Ok (Success x)
          | Inter.HandlingError _
          | Inter.Rejected        -> Error checkpoint
          | Inter.Shifting _
          | Inter.AboutToReduce _ ->
              check_for_error (Inter.resume checkpoint)

        (* Returns recovered parser after feeding with the [token] or
           intermediate step with the same candidates and checkpoint
           if recovery fails. *)

        let try_recovery failure_cp candidates token : 'a step =
          match R.attempt candidates token with
            `Ok (Inter.InputNeeded _ as cp, _) -> Intermediate (Correct cp)
          | `Ok (cp, _) ->
               let msg = Printf.sprintf
                           "Recovery failed: \
                            Unexpected result of function [attempt]:\n%s"
                           (inputNeededExpected cp)
               in InternalError msg
          | `Accept x -> Success x
          | `Fail ->
             match token with
               token, _, _ when Lexer.Token.is_eof token ->
                begin match candidates.final with
                  Some x -> Success x
                | None ->
                    InternalError "Recovery failed: No recovery on EOF."
                end
               (* Skip the token and return control to the user to try again
                  at the next step *)
             | _ -> Intermediate (Recovering (failure_cp, candidates))

        (* The function [step] feeds the parser a [token] and returns
           the next intermediate step or result. *)

        let step (parser : 'a intermediate_step) failure token
          : 'a step * message option =
          match parser with
            Correct (InputNeeded env as cp) ->
              (* If the parser is in a correct checkpoint (i.e. in
                 [InputNeeded]) feed with [token] like in simple
                 [loop_handle] from the MenhirLib *)

              begin match check_for_error (Inter.offer cp token) with
                Ok s -> s, None
              | Error failure_cp ->
                  let error = failure failure_cp in
                  let () = TracingPrinter.print
                           @@ Printf.sprintf "Error %s\n" error.Region.value in
                  let candidates = R.generate env in
                  try_recovery failure_cp candidates token, Some error
              end
          | Correct cp ->
              let msg = "Impossible case:\n" ^ (inputNeededExpected cp)
              in InternalError msg, None
          | Recovering (failure_cp, candidates) ->
              try_recovery failure_cp candidates token, None

        (* The function [loop_handle] s similar to [loop_handle] from
           MenhirLib but with error recovery *)

        let loop_handle
          (lexbuf   : Lexing.lexbuf)
          (success  : 'a -> 'a)
          (failure  : 'a Inter.checkpoint -> message)
          (supplier : unit -> token * Lexing.position * Lexing.position)
          (initial  : 'a Inter.checkpoint)
          : (Parser.tree * message list, message Ne.t) result =
          let initial = Correct initial in
          let errors : message list ref = ref []
          in
          let rec loop parser =
            match supplier () with
              exception LexingError error ->
                Error Ne.(error.message ::!errors)
            | token ->
                let result =
                  match step parser failure token with
                    res, Some error -> errors := error::!errors; res
                  | res, None       -> res in
                match result with
                  Success x            -> Ok (success x, !errors)
                | Intermediate parser  -> loop parser
                | InternalError msg    ->
                    let value     = "Internal error: " ^ msg in
                    let region, _ = get_current_token_region lexbuf in
                    let fst_msg   = Region.{value; region}
                    in Error Ne.(fst_msg :: !errors)
          in loop initial
      end

    let get_message_on_failure lexbuf (module ParErr : PAR_ERR) checkpoint =
      let value     = get_error_message (module ParErr) checkpoint
      and region, _ = get_current_token_region lexbuf
      in Region.{value; region}

    let incr_menhir_recovery ~no_colour lexbuf_of (module ParErr : PAR_ERR) source =
      let lexbuf       = lexbuf_of source in
      let supplier     = lexer_lexbuf_to_supplier
                           Debug.mode (menhir_lexer ~no_colour) lexbuf in
      let failure      = get_message_on_failure lexbuf (module ParErr) in
      let interpreter  = Recover.loop_handle lexbuf success failure supplier in
      let module Incr  = Parser.Incremental in
      let parser       = Incr.main lexbuf.Lexing.lex_curr_p in
      let result       = interpreter parser
      in result

    let recov_from_lexbuf  ~no_colour = incr_menhir_recovery ~no_colour (fun x -> x)
    let recov_from_channel ~no_colour = incr_menhir_recovery ~no_colour Lexing.from_channel
    let recov_from_string ~no_colour  = incr_menhir_recovery ~no_colour Lexing.from_string

    let recov_from_file ~no_colour (module ParErr : PAR_ERR) path =
      match lexbuf_from_file path with
        Error error ->
          Error (Ne.singleton error.message)
      | Ok (lexbuf, close) ->
          let result = recov_from_lexbuf ~no_colour (module ParErr) lexbuf
          in (close (); result)
  end
